
## **1 | DialoGPT란 무엇인가?**

- **출신** : Microsoft Research가 2019년에 GPT-2를 대화용으로 특화시켜 공개한 오픈-소스 LM.
    
- **학습 데이터** : 2005–2017 Reddit 다중 턴 대화 147 백만 건으로 사전학습해 “사람 같은” 단일턴 응답 품질을 달성함  .
    
- **모델 크기** :
    
    - _small_ 117 M
        
    - _medium_ 345 M
        
    - _large_ 762 M 
        
        (다운로드, fine-tune, 로컬 추론이 모두 가능).



- **라이선스** : MIT—상업 게임에도 포함 가능(표시 의무만 지키면 됨)  .
 _2005년부터 2017년까지 Reddit 댓글 체인에서 추출한 1억 4,700만 건의 대화 유사 대화를 기반으로 학습된 DialoGPT는 Hugging Face PyTorch 변환기를 확장하여 단일 턴 대화 환경에서 자동 및 인간 평가 측면에서 인간에 가까운 성능을 달성합니다. DialoGPT를 활용하는 대화 시스템은 강력한 기준 시스템보다 더욱 관련성 있고, 내용이 풍부하며, 맥락에 일관된 반응을 생성함을 보여줍니다. 사전 학습된 모델과 학습 파이프라인은 신경 반응 생성 연구 및 더욱 지능적인 오픈 도메인 대화 시스템 개발을 지원하기 위해 공개됩니다._

- **자기 회귀 모델**이란?

자기 회귀 모델은 시퀀스의 이전 입력에서 측정값을 가져와 시퀀스의 다음 성분을 자동으로 예측하는 [기계 학습(ML)](https://aws.amazon.com/what-is/machine-learning/) 모델의 클래스입니다. 자기 회귀는 시계열 분석에 사용되는 통계 기법으로, 시계열의 현재 값이 과거 값의 함수라고 가정합니다. 자기 회귀 모델은 유사한 수학적 기법을 사용하여 시퀀스에 있는 요소 간의 확률적 상관관계를 판단합니다. 그런 다음 도출된 정보를 사용하여 알려지지 않은 시퀀스의 다음 요소를 추측합니다. 예를 들어 자기 회귀 모델이 훈련 중에 여러 영어 문장을 처리하여 단어 ‘_is’_가 항상 ‘_there’라는 단어 뒤에 오는 것을 파악합니다._ 그런 다음 ‘there _is_’가 함께 있는 새 시퀀스를 생성합니다_._
