### GARField: Group Anything with Radiance Fields (논문 핵심 내용 정리)

#### **1. 목표 (Goal)**

이 논문의 목표는 여러 장의 2D 이미지로부터 3D 장면을 복원하면서, 그 안에 있는 객체들을 **의미 있는 계층적 그룹(hierarchy of semantically meaningful groups)으로 분해**하는 것입니다.

여기서 핵심은 **"그룹화의 모호성(ambiguity of grouping)"** 을 다루는 것입니다. 예를 들어, 굴착기의 '바퀴'는 독립된 부품으로 볼 수도 있고, '굴착기 전체'의 일부로 볼 수도 있습니다. GARField는 이러한 여러 수준의 분해(decomposition)를 모두 표현하고 추출하는 것을 목표로 합니다.

---

#### **2. 핵심 아이디어: 물리적 스케일(Physical Scale)을 이용한 그룹화**

GARField는 그룹화의 모호성을 해결하기 위해 **"물리적 스케일(physical scale)"**이라는 개념을 도입합니다.

1.  **스케일 조건부 특징 필드 (Scale-Conditioned Feature Field)**:
    *   3D 공간의 각 지점 `(x, y, z)`에 대해, 단순히 하나의 특징(feature)만 저장하는 것이 아니라, **'스케일 값'** 을 추가로 입력받는 3D 특징 필드를 최적화합니다.
    *   즉, `(x, y, z, scale)`을 입력하면 해당 지점의 특징이 출력됩니다.
    *   여기서 **스케일**은 우리가 보고자 하는 그룹의 크기를 의미합니다. (예: 작은 스케일 = 바퀴, 큰 스케일 = 굴착기 전체)

2.  **SAM 마스크를 이용한 학습**:
    *   입력된 여러 2D 이미지들을 **SAM(Segment Anything Model)** 에 넣어 다양한 크기와 종류의 2D 마스크(mask)들을 대량으로 추출합니다.
    *   GARField는 이 2D 마스크들을 감독(supervision) 신호로 사용하여, 3D 공간의 '스케일 조건부 특징 필드'를 학습시킵니다.
    *   **핵심**: 서로 다른 시점에서 본 이미지에서 추출된 마스크들이 서로 충돌하거나 모순될 수 있습니다. GARField는 **'스케일'** 정보를 기준으로 이 마스크들을 일관성 있게 3D 공간에 융합(fuse)합니다. 예를 들어, 한 뷰에서는 바퀴만 보이고 다른 뷰에서는 굴착기 전체가 보일 때, 이를 각각 작은 스케일과 큰 스케일의 정보로 구분하여 학습에 반영합니다.

---

#### **3. 작동 방식 및 결과**

1.  **계층적 그룹 추출**:
    *   학습이 완료된 특징 필드로부터, 사용자는 원하는 그룹을 추출할 수 있습니다.
    *   **자동 트리 구성**: 전체 장면을 구성하는 그룹들의 계층 구조(예: 도시 -> 건물 -> 창문)를 자동으로 만들 수 있습니다.
    *   **사용자 상호작용**: 사용자가 3D 공간의 한 점을 클릭하고 원하는 '스케일'을 지정하면, 그에 해당하는 3D 그룹(예: 바퀴, 또는 굴착기 전체)을 즉시 얻을 수 있습니다.

2.  **GARField의 장점**:
    *   **다중 뷰 일관성 (Multi-view Consistency)**: 여러 시점에서 봐도 일관된 3D 그룹을 제공합니다. 입력으로 사용된 SAM의 2D 마스크보다 더 정교하고 노이즈가 적은 결과를 보여줍니다.
    *   **계층적 분해**: 객체의 부분(subpart), 전체 객체(object), 객체들의 군집(cluster of objects) 등 다양한 수준의 그룹을 모두 표현하고 추출할 수 있습니다.
    *   **제로샷(Zero-shot) 능력**: SAM의 능력을 이어받아, 특정 객체에 대해 미리 학습하지 않아도 "in-the-wild"의 다양한 장면에 대해 효과적으로 작동합니다.

---

#### **4. 상세 방법론 (Detailed Methodology)**

GARField의 방법론은 크게 세 단계로 구성됩니다.

**A. 3D 장면 표현 (Scene Representation)**

- GARField는 3D 장면을 표현하기 위해 NeRF를 기반으로 하되, K-Planes와 같은 최신 평면 기반(plane-based) 표현 방식을 사용합니다. 이는 더 빠른 학습과 렌더링을 가능하게 합니다.
- 3D 공간의 각 점 `(x,y,z)`는 다음과 같은 정보들을 갖도록 모델링됩니다:
    - **밀도 (Density)**: 물체의 형태를 결정.
    - **색상 (Color)**: 물체의 외형을 결정.
    - **유사도 특징 (Affinity Feature)**: **(핵심!)** 해당 점의 그룹 소속 정보를 담는 고차원 벡터. 이 특징은 아래 설명할 '스케일' 값에 따라 동적으로 변합니다.

**B. 스케일 조건부 유사도 필드 학습 (Learning a Scale-Conditioned Affinity Field)**

- **핵심 아이디어**: 그룹화의 모호성을 해결하기 위해, 3D 공간의 한 점이 고정된 그룹 정보를 갖는 것이 아니라 **'물리적 스케일'에 따라 다른 그룹 소속감을 갖도록** 합니다.
- **스케일 조건부 특징 필드**: 모델은 `(x, y, z, scale)`을 입력받아, 해당 스케일에 맞는 `유사도 특징 벡터`를 출력합니다.
    - **작은 `scale`** 입력 → **작은 그룹(예: 타이어)** 내에서의 소속감을 나타내는 특징 출력.
    - **큰 `scale`** 입력 → **큰 그룹(예: 자동차 전체)** 내에서의 소속감을 나타내는 특징 출력.
- **학습 데이터**: 입력된 2D 이미지들로부터 **SAM(Segment Anything Model)**을 이용해 수백만 개의 다양한 2D 마스크를 추출합니다. 각 마스크의 3D 공간상 물리적 크기(스케일)도 함께 추정합니다.
- **학습 방식 (대조 학습, Contrastive Learning)**: 
    1.  하나의 2D 마스크와 해당 스케일 `s`를 선택합니다.
    2.  **긍정 쌍 (Positive Pair)**: 마스크 **내부**에서 두 점을 샘플링합니다. 이 두 점은 스케일 `s`에서 같은 그룹이므로, 모델이 출력하는 두 특징 벡터가 **비슷해지도록** 학습시킵니다.
    3.  **부정 쌍 (Negative Pair)**: 마스크 **내부**에서 한 점, **외부**에서 한 점을 샘플링합니다. 이 두 점은 다른 그룹이므로, 두 특징 벡터가 **달라지도록** 학습시킵니다.
    4.  이 과정을 모든 마스크와 스케일에 대해 반복하며, 모델은 점차 3D 공간의 그룹 구조를 학습하게 됩니다.

**C. 계층적 그룹 추출 (Extracting Hierarchical Groups)**

- 학습된 필드로부터 다음과 같은 방식으로 그룹을 추출합니다.
- **사용자 상호작용 기반**: 사용자가 3D 뷰에서 한 점을 클릭하고 **스케일 슬라이더**를 조절하면, 현재 스케일에서 클릭된 점과 유사도가 높은 모든 점들이 실시간으로 그룹화되어 시각화됩니다.
- **자동 계층 트리 구성**: 가장 작은 스케일부터 시작하여 강하게 묶이는 클러스터들을 찾고, 스케일을 점차 키워나가며 클러스터들을 병합하는 과정을 반복합니다. 이를 통해 장면 전체가 하나의 루트가 되는 계층적 트리(dendrogram)를 자동으로 생성할 수 있습니다.

---

#### **5. 결론 및 기여**

*   **3D 장면 분해의 새로운 패러다임**: SAM을 3D NeRF와 결합하여, 복잡한 3D 장면을 의미 있는 계층적 그룹으로 분해하는 새로운 방법을 제시했습니다.
*   **'스케일'을 통한 모호성 해결**: 물리적 스케일이라는 직관적인 개념을 도입하여, 객체 그룹화에 내재된 모호성 문제를 효과적으로 해결했습니다.
*   **다양한 다운스트림 응용 가능성**: 이렇게 추출된 계층적 3D 그룹 정보는 3D 에셋 추출, 동적 장면 이해, 로보틱스 등 다양한 후속 연구에 매우 유용하게 사용될 수 있습니다.