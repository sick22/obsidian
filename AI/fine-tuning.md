
## Fine-tunig이란?

	pre-train된 모델을 조정한 정도에 따라 두가지로 분류
- Full Fine-Tuning
	작업과 모델에 큰 차이가 있는 경우 진행
- Repurposing
	작업과 모델이 유사성이 있거나 데이터셋이 작은 경우

## 한계

1. 데이터 품질과 양 : 고품질의 데이터가 불충분할 경우 overfitting 발생
2. 높은 비용 : 고성능의 하드웨어
3. 지식 소실(catastrophic Forgetting) : 기존 모델의 지식 소실 가능성
4. 일반화의 어려움 : 특정 도메인에 과하게 최적화 되어 범용성 하락

## 유형

지도학습 (supervised Fine-Tuning) SFT
비지도학습 (unsupervised Fine-Tuning) UFT

**UFT**
	(때려박기) 라벨이 없는 데이터를 학습 -> 데이터의 구조 활용, 표현력 향상
**SFT**
	라벨이 있는 고품질 데이터를 학습(정답이 포함된 데이터셋) -> 특정 목적에 맞춤형, 성능 최적화 

SFT dataset 은 입력과 정답이 존재해야 트레이닝 가능

1. Pre-training 을 통해 모델의 언어에 대한 이해 능력과 맥락 파악 능력 장착
2. SFT를 통해 특정 분야에 대한 능력 향상

### Pre-training
- 용도 **|** 자연어 처리와 같은 일반화 가능한 기술에 대한 모델 학습
- 데이터 요구 사항 **|** 데규모 도메인 데이터 셋(reddit)
- 결과 **|** 일반화된 기초 모델(base model)
Fine-Tuning
-  용도 **|** 특정 목적에 맞춰 LLM을 조정 
- 데이터 요구 사항 **|** 소규모의 고품질 데이터 셋, 특정 사용 사례
- 결과 **|** 특정 작업 및 도메인에 맞게 성능 조정됨