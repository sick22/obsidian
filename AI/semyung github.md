# 제너럴브릿지 인턴십 

## I.프로젝트 개요
- 수행일자 : 2025.06.30 ~
- 프로젝트명 : 미정
- 주제 : DialoGPT와 PyTorch를 사용하여 대화형 채팅 생성 모델 구축
  
    | 구분 | 성명 | 학번 | 소속학과 |     
    |-----|-----|----|----|
    | 팀장 | 문규성 | | AI학과 |
    | 팀원 | 정다빈 | | AI학과 |
    | 팀원 | 송민서 | | 컴퓨터공학과 |
    | 팀원 | 정용석 | | 컴퓨터공학과 |
---
## II.


# **DialoGPT란?**

  

DialoGPT는 Reddit 댓글·토론 스레드에서 추출한 **약 1억 4,700만 건**의 대화를 학습한 **GPT-2 기반 대화형 언어 모델**입니다. 기본 아키텍처는 GPT-2와 동일하게 **트랜스포머(Transformer)** 디코더 스택을 사용하지만, 학습 데이터가 **일반 웹 문서**가 아닌 **온라인 대화**라는 점이 가장 큰 차이점입니다.

  

## **DialoGPT와 GPT-2 비교**

|**구분**|**GPT-2**|**DialoGPT**|
|---|---|---|
|**훈련 데이터**|위키·웹 문서 등 일반 텍스트|Reddit 대화 1.47억 건|
|**모델 목적**|범용 언어 생성|대화형 응답 생성|
|**튜닝 방식**|언슈퍼바이즈드 LM|GPT-2 → 대화 데이터로 추가 파인튜닝|

> **핵심 포인트**

> DialoGPT는 *“대화용”*에 특화되도록 GPT-2를 파인튜닝한 버전으로 이해하시면 됩니다.

---

## **GPT-2 아키텍처 요약**

GPT-2는 아래와 같이 두 가지 블록으로 구성됩니다.
![GPT-2 아키텍처](file:///Users/jeong-yongseog/Desktop/DialoGPT/%E1%84%80%E1%85%A8%E1%84%8E%E1%85%B3%E1%86%BC.avif)

1. **인코더(Encoder)** – Self-Attention 레이어와 **Feed-Forward Neural Network**(FFNN)로 이루어져 있습니다.
    
2. **디코더(Decoder)** – 인코더와 구조는 유사하지만, **마스킹된** Self-Attention을 사용하여 **미래 토큰을 참조하지 못하도록** 설계되어 있습니다. 이는 곧 **자기 회귀** 특성을 의미합니다.
    

  

### **Self-Attention과 마스킹된 Self-Attention의 차이**

- 일반 Self-Attention은 현재 토큰의 **왼쪽과 오른쪽**을 모두 참고할 수 있습니다.
    
- 반면 **마스킹된** Self-Attention은 현재 시점 **오른쪽(미래)** 토큰을 가려서 **순차적** 예측만 가능하도록 합니다.


| 구분         | Self‑Attention(비마스킹)        | Masked Self‑Attention(=Causal)          |
| ---------- | --------------------------- | --------------------------------------- |
| **목적**     | 입력 시퀀스 전(全) 위치 간 관계 학습      | 미래 토큰 정보 차단, 순차적 생성 보장                  |
| **마스킹 행렬** | 없음 (모든 위치에 Attention 가능)    | 상삼각(triu) 마스크로`t+1`이후를 0 처리           |
| **사용 위치**  | 트랜스포머**인코더**, BERT류 양방향 LM | 트랜스포머**디코더**, GPT류 자기 회귀 LM            |
| **시간 복잡도** | $O(n^2)$                    | $O(n^2)$ (계산량은 동일, 유효 attention 수는 ↓)   |
| **장점**     | 풍부한 전·후방 문맥 활용 → 문맥 이해에 강점  | 정보 누설 방지 → 자연스러운 토큰 생성 가능               |
| **단점**     | 방향성 불분명 → 생성 과제에 직접 사용 어려움  | 단방향(one‑way) 정보 흐름 → 긴 의존 학습이 상대적으로 어려움 |

---

## **GPT-2 내부 계층 구성**

1. **임베딩(Embedding) 계층** – 입력 토큰을 고정 길이 벡터로 변환합니다.
    
2. **트랜스포머 디코더 스택** – 마스킹된 Self-Attention과 FFNN으로 이루어진 블록을 여러 층 반복합니다.
    
3. **출력(Output) 계층** – 디코더 출력을 다시 단어 확률 분포로 변환합니다.
    

---

## **자기 회귀(Autoregressive) 모델이란?**

  

> “지금까지 입력된 토큰만 보고 **다음 토큰**을 예측”하는 모델 계열입니다.

  

- 과거 값(토큰)을 기반으로 **확률적 상관관계**를 학습합니다.
    
- 시계열 분석의 **자기 회귀(AR)** 기법과 동일한 수학적 아이디어를 활용합니다.
    
- 예시: 모델이 훈련 중 there 뒤에 is가 자주 등장한다는 패턴을 학습한 경우, 새로운 문장을 생성할 때 there is를 자연스럽게 출력합니다.
    

  

따라서 GPT 계열 모델은 **왼쪽에서 오른쪽**으로 토큰을 하나씩 생성하며 문장을 완성합니다.

---

**GPT-2 및 dialogGPT 아키텍처**의 구조는 아래와 같습니다.


![dialogGPT 아키텍처](file:///Users/jeong-yongseog/Desktop/DialoGPT/%E1%84%8B%E1%85%A1%E1%84%8F%E1%85%B5%E1%84%90%E1%85%A6%E1%86%A8%E1%84%8E%E1%85%A5.avif)


위 모델은 트랜스포머 아키텍처를 기반으로 하기 때문에 반복 및 입력 복사 문제가 발생합니다.
ㅁㅇ

| **구분**                 | **근본 원인**                                                                                                                                                                                    | **세부 메커니즘**                                                                   |
| ---------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------- |
| **모델 내부 확률 분포의 편향**    | 1. **자기 회귀 학습 목표(MLE)**  · 다음 토큰 하나씩 예측 → “가장 자주 본 패턴”에 확률 질량 집중.2. **데이터 편향**  · Reddit 대화에는 맞장구·클리셰(“Yeah”, “Exactly”) 같은 단순 반복이 많음 → 그대로 학습.                                              | _Softmax_가 높은 빈도 토큰에 과도한 확률을 부여 → 디코더가 **짧은 루프(같은 단어·문장 반복)**를 “안전한 선택”으로 간주. |
| **Self-Attention 피드백** | 3. **마스킹된 Self-Attention의 자기 강화**  · 방금 만든 토큰이 _Context_로 즉시 들어가며, 그 토큰에 높은 주의(attention)가 쏠림.  · 이전 스텝에서 방출한 단어가 다시 가장 유력한 후보로 떠오를 가능성 ↑                                                    | 토큰이 한 번 반복되면, 다음 스텝에서 **유사 토큰을 또 생성**하기 쉬워져 “무한 반복”에 빠지기 쉽습니다.                |
| **디코딩 전략 한계**          | 4. **Greedy / Beam Search의 모드 붕괴**  · 확률이 조금만 치우쳐도 같은 경로를 끝까지 추적 → 다양성 손실.5. **Repetition Penalty 부재**  · 기본 GPT-2 API는 n-gram blocking, frequency penalty가 설정돼 있지 않음.                       | 탐색 공간에서 **다양성을 강제할 규칙이 없으면** 확률 고점(high-prob) 루프에 빠짐.                         |
| **입력·출력 간 어텐션 패턴**     | 6. **Copy Bias**  · 대화 데이터에는 질문-답변 간 어휘 중복이 빈번해 *“입력을 그대로 돌려주는 것”*도 통계적으로 합리적인 예측.7. **Position Encoding의 상대적 거리 문제**  · 입력 문장이 디코더 스택 상단까지 올라오지 않기 때문에, **가장 최근 토큰**(사용자 입력의 끝부분)에 가중치가 몰림. | 그 결과 디코더가 **사용자 마지막 문장을 그대로 에코**하거나, 일부 구문만 살짝 바꿔 재출력하기 쉽습니다.                 |

- Top-K 샘플링 – 가장 가능성이 높은 다음 단어 K개를 필터링하고 확률 질량을 해당 다음 단어 K개에만 재분배합니다.
- Top-p 샘플링은 가장 가능성이 높은 K개의 단어만을 선택하는 것이 아니라 누적 확률이 확률 p를 초과하는 가장 작은 단어 집합을 선택합니다.

그런 다음 확률 질량이 단어 집합에 있는 단어들 사이에 재분배됩니다. 결과적으로, 단어 집합의 크기는 다음 단어의 확률 분포에 따라 동적으로 증가하거나 감소할 수 있습니다.