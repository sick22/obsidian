# 3D 장면 복원 및 생성 기술 요약

이 문서는 NeRF, BARF, Gaussian Splatting, GARF와 같은 최신 3D 장면 복원 및 생성 기술과 3D 그래픽스의 핵심 개념인 계층(Hierarchy)에 대해 요약합니다.

---

## 1. NeRF (Neural Radiance Fields)

- **요약**: 여러 장의 2D 이미지와 **정확한 카메라 위치**를 이용해 고품질의 3D 장면을 생성하는 기술.
- **작동 방식**: 신경망이 3D 공간의 특정 좌표(x, y, z)와 방향을 입력받아 해당 지점의 색상(RGB)과 밀도(density)를 출력하도록 학습합니다.
- **핵심 특징**:
    - 매우 사실적인 결과물.
    - 렌더링 시 새로운 시점의 이미지를 생성.
    - **정확한 카메라 정보가 필수적**입니다.

---

## 2. BARF (Bundle-Adjusting Radiance Fields)

- **요약**: NeRF를 개선하여 **부정확한 카메라 위치**를 스스로 보정하며 3D 장면을 생성하는 기술.
- **작동 방식**: 3D 장면을 학습하는 동시에, 입력된 이미지들의 카메라 위치를 번들 조정(Bundle Adjustment) 기법으로 최적화합니다.
- **핵심 특징**:
    - 부정확한 카메라 정보로도 고품질 결과물 생성 가능.
    - 3D 장면과 카메라 위치를 동시에 학습.

---

## 3. Gaussian Splatting (가우시안 스플래팅)

- **요약**: 3D 공간을 수많은 작은 '3D 가우시안 입자'의 집합으로 표현하여 3D 장면을 복원하는 기술.
- **작동 방식**: 각 입자는 위치, 크기, 모양, 색상, 투명도 정보를 가지며, 이 입자들을 2D 이미지 평면에 '뿌려서(splatting)' 새로운 뷰를 생성합니다.
- **핵심 특징**:
    - **매우 빠른 렌더링 속도 (실시간 가능)**.
    - NeRF와 동등하거나 그 이상의 고품질.
    - NeRF의 강력한 대안으로 부상하고 있습니다.

---

## 4. GARF (Generative Articulated Radiance Fields)

- **요약**: **관절이 있어 움직이는 대상(사람, 동물 등)** 의 3D 모델을 만들고, 그 **포즈를 자유롭게 제어**할 수 있는 기술.
- **작동 방식**: 대상의 기준 자세(canonical pose)와 다른 포즈로의 변형(deformation)을 함께 학습하여, 새로운 포즈 값을 입력받아 해당 모습을 렌더링합니다.
- **핵심 특징**:
    - **동적(Dynamic)** 이고 **관절(Articulated)** 이 있는 대상을 다룸.
    - 3D 모델의 포즈 제어 및 애니메이션에 특화됨.

---

## 5. 계층 (Hierarchy)

3D 그래픽스에서 계층은 두 가지 주요 맥락에서 사용됩니다.

### 5.1. 장면 구성을 위한 계층 (Scene Graph)

- **목적**: 객체 간의 부모-자식 관계를 정의하여 복잡한 움직임을 쉽게 만들고 장면을 효율적으로 관리.
- **예시**: 사람 캐릭터의 뼈대(Skeleton). 부모인 허벅지를 움직이면 자식인 정강이와 발이 따라 움직임.
- **관련 기술**: GARF

### 5.2. 표현의 효율성을 위한 계층 (Hierarchical Representations)

- **목적**: 도시처럼 거대한 장면을 여러 개의 작은 모델(LOD - Level of Detail)로 나누어 효율적으로 표현하고 렌더링.
- **예시**: Block-NeRF. 멀리서는 저해상도 모델을, 가까이서는 고해상도 모델을 보여줌.
- **관련 기술**: NeRF, Gaussian Splatting의 대규모 장면에 대한 확장.

---

## 6. 관련 컴퓨터 과학 개념

### 6.1. 해시 테이블 (Hash Table)

- **요약**: 키(Key)와 값(Value)을 쌍으로 저장하는 자료구조로, **매우 빠른 데이터 검색, 삽입, 삭제**가 특징입니다.
- **핵심 원리**: 해시 함수(Hash Function)를 사용해 키를 배열의 특정 인덱스로 변환하여 데이터에 한번에 접근합니다. (시간 복잡도 평균 O(1))
- **주요 이슈**: 해시 충돌(Hash Collision). 서로 다른 키가 같은 인덱스를 가리키는 문제이며, 주로 **체이닝(Chaining)**이나 **개방 주소법(Open Addressing)**으로 해결합니다.

---

## 7. 2D/3D 분할 (Segmentation) 및 그룹화 (Grouping) 모델

### 7.1. SAM (Segment Anything Model)

- **요약**: 2D 이미지 안의 **어떤(Anything) 객체라도** 사용자의 간단한 지시(클릭, 박스 등)를 통해 정확하게 분리(Segment)해내는 범용 모델.
- **핵심 특징**:
    - **제로샷(Zero-shot) 일반화**: 특정 객체를 따로 학습하지 않아도 처음 보는 객체를 분할 가능.
    - **프롬프트 기반(Promptable)**: 사용자의 상호작용에 즉각 반응.
    - 컴퓨터 비전의 파운데이션 모델로 평가받음.

### 7.2. GARField (Group Anything with Radiance Fields)

- **요약**: SAM을 3D로 확장하여, 3D 장면을 **의미 있는 계층적 그룹(hierarchy of groups)으로 분해**하는 기술.
- **핵심 아이디어**: **물리적 스케일(physical scale)** 개념을 도입하여 그룹화의 모호성을 해결. 사용자가 원하는 스케일(예: 작은 스케일=바퀴, 큰 스케일=자동차)에 따라 해당하는 3D 그룹을 추출.
- **작동 방식**: SAM에서 추출한 다양한 2D 마스크들을 '스케일' 정보를 기준으로 3D 공간에 일관성 있게 융합하여 학습.
- **결과물**: 3D 포토샵처럼, 장면을 구성요소(에셋, 파트, 군집 등)별로 분리할 수 있는 계층적 3D 맵.

### 7.3. 모델별 역할 비교: SAM vs. GARF vs. GARField

- **SAM**: **2D 이미지**에서 **단일 객체의 경계선**을 찾아 분리하는 '누끼따기 전문가'. 객체의 부분이나 의미는 모름.
- **GARF**: **움직이는 3D 아바타**를 만들고 **포즈를 제어**하는 '인형술사'. 관절 구조를 이해하여 팔, 다리 등 파트별 제어 가능.
- **GARField**: **정적인 3D 장면**을 **구성요소별로 분해**하고 이해하는 '3D 해부학자'. 장면을 건물, 창문, 자동차 등 의미있는 레이어로 나눔.

