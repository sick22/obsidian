암 환자를 구분할 때는 recall을 높혀야함
동영상 추천 모델을 만들 때는 precision을 높혀야함

간단히 말해, **Control은 '기존의 것'** 이고 **Variation은 '새롭게** 

  **테스트하려는 것'**입니다.
  ---

  

  **1. Control (컨트롤, 대조군, A 그룹)**


   * **정의:** 현재 사용자들에게 제공되고 있는 원래 버전의 웹페이지, 앱 화면,

     기능 등을 의미합니다.

   * **역할:** **성과 측정의 기준선(Baseline)** 역할을 합니다. 새로운

     변화(Variation)가 얼마나 더 나은지, 혹은 나쁜지를 판단하기 위한

     비교의 기준이 됩니다.

   * **특징:** 아무런 변경을 가하지 않은 상태입니다. 만약 테스트가 없다면 모든

      사용자가 경험하게 될 바로 그 버전입니다.


  **2. Variation (베리에이션, 실험군, B 그룹)**

   * **정의:** 특정 가설을 검증하기 위해 기존 버전(Control)의 한 가지 요소를

     변경한 새로운 버전입니다.

   * **역할:** **가설을 증명하거나 반증하기 위한 실험 대상**입니다. Control 대비

     성과가 어떻게 달라지는지를 측정하게 됩니다.

   * **특징:** 버튼 색상, 문구, 이미지, 레이아웃 등 테스트하고 싶은 '단 하나의

      요소'만 변경된 버전이어야 합니다. (만약 여러 요소를 바꾸면 어떤

     요소가 성과에 영향을 미쳤는지 알 수 없기 때문입니다.)
  ---

  

  **핵심 비교 표**

  
| 구분          | Control (대조군)       | Variation (실험군)                |
| ----------- | ------------------- | ------------------------------ |
| **목적**      | 성과 비교를 위한 **기준선**   | 가설 검증을 위한 **실험 대상**            |
| **내용**      | **기존 버전** (변경 없음)   | **새로운 버전** (특정 요소 변경)          |
| **사용자 그룹**  | 전체 트래픽의 일부 (예: 50%) | 전체 트래픽의 나머지 (예: 50%)           |
| **가설과의 관계** | 현재 상태               | "만약 ~을 바꾼다면, ~가 개선될 것이다" 라는 가설 |

  ---

  

  **간단한 예시: "구매하기" 버튼 색상 변경**


  온라인 쇼핑몰에서 "구매하기" 버튼의 클릭률을 높이고 싶다고 가정해

  보겠습니다.

   * **가설:** "구매하기 버튼을 현재의 파란색에서 더 눈에 띄는 녹색으로

     바꾸면, 클릭률이 10% 증가할 것이다."

  이 가설을 검증하기 위한 A/B 테스트는 다음과 같이 설계됩니다.

   * **Control (A 그룹):** 기존의 **파란색 "구매하기" 버튼**이 있는 페이지.

   * **Variation (B 그룹):** **녹색 "구매하기" 버튼**으로 변경된 페이지.


  **실행:**

   1. 웹사이트 방문자를 무작위로 두 그룹으로 나눕니다.

   2. A 그룹에게는 Control 페이지를, B 그룹에게는 Variation 페이지를

      보여줍니다.

   3. 일정 기간 동안 각 그룹의 "구매하기" 버튼 클릭률 데이터를 수집합니다.

  

  **결과 분석:**

   * 만약 Variation(녹색 버튼)의 클릭률이 Control(파란색 버튼)보다

     통계적으로 유의미하게 높다면, 가설이 입증된 것이므로 모든 사용자에게

     녹색 버튼을 적용하는 결정을 내릴 수 있습니다.

   * 만약 차이가 없거나 오히려 낮다면, 기존의 파란색 버튼을 유지합니다.



  결론적으로, **Control과 Variation의 차이는 바로 '테스트하고자 하는 변화** 

  **그 자체'**입니다. 이 둘을 비교함으로써 우리는 감이나 추측이 아닌, 실제

  데이터에 기반한 객관적인 의사결정을 내릴 수 있게 됩니다.

---

# 오프라인 테스트와 교차 검증

> **핵심 요약**: **오프라인 테스트**는 모델을 실제 서비스에 배포하기 전에 **미리 준비된 데이터셋으로 성능을 검증하는 전체 과정**을 의미합니다. **교차 검증**은 그 과정 속에서 **모델의 성능을 더 신뢰성 있게 측정하기 위한 구체적인 기술(Technique)**입니다.

---

### **1. 오프라인 테스트 (Offline Test)**

#### **(1) 개념**
오프라인 테스트는 모델이 실시간 데이터가 아닌, **과거에 수집된 정적인 데이터(historical data)를 사용**하여 성능을 평가하는 모든 활동을 말합니다. '실험실 환경'에서 진행되는 테스트이며, 온라인 테스트(A/B 테스트 등)와 대비되는 개념입니다.

#### **(2) 목적**
*   **안전성 및 비용**: 실제 사용자에게 영향을 주지 않고, 비용과 시간을 아끼며 모델의 성능을 안전하게 측정합니다.
*   **빠른 반복**: 다양한 모델 구조나 하이퍼파라미터를 빠르게 실험하고 비교하며 최적의 모델을 탐색합니다.
*   **최소 성능 보장**: 실제 서비스에 배포할 가치가 있는지, 최소한의 성능 기준을 만족하는지 확인하는 '필터' 역할을 합니다.

#### **(3) 일반적인 과정**
1.  **데이터 준비**: 평가에 사용할 과거 데이터를 수집하고 정제합니다.
2.  **데이터 분할**: 전체 데이터를 **훈련(Train) / 검증(Validation) / 테스트(Test) 세트**로 분할합니다.
3.  **모델 학습 및 평가**: 훈련 세트로 모델을 학습시키고, 테스트 세트로 최종 성능(정확도, RMSE 등)을 측정합니다.

#### **(4) 한계**
*   **과거와 미래의 차이**: 오프라인 테스트에 사용된 과거 데이터의 패턴과, 모델이 앞으로 마주할 실제 데이터의 패턴이 다를 수 있습니다(Data Drift).
*   **실시간 상호작용 부재**: 모델의 예측이 실제 사용자 행동에 미치는 영향(Feedback Loop)을 측정할 수 없습니다.

---

### **2. 교차 검증 (Cross-Validation, CV)**

#### **(1) 개념**
교차 검증은 데이터를 한 번만 나누어 평가할 때 발생할 수 있는 **편향(bias)과 변동성(variance)을 줄이기 위한 평가 기법**입니다. 데이터를 여러 번 다른 방식으로 나누어 반복적으로 학습하고 평가하여, 모델의 성능을 보다 일반화되고 안정적으로 측정합니다.

#### **(2) 필요성**
데이터를 한 번만 나눌 경우, **우연히** 테스트 세트가 쉽거나 어려워서 성능이 왜곡될 수 있습니다. 교차 검증은 **여러 번의 모의고사를 보고 그 평균 점수로 실력을 판단**하는 것과 같이, 이러한 우연성을 줄여줍니다.

#### **(3) K-겹 교차 검증 (K-Fold Cross-Validation) 과정**
1.  **데이터 분할**: 훈련 데이터를 비슷한 크기의 **K개**의 부분집합(Fold)으로 나눕니다. (보통 K=5 또는 10 사용)
2.  **반복 학습 및 평가**: 총 K번의 반복을 수행합니다.
    *   각 반복마다 하나의 Fold를 **검증 세트**로, 나머지 K-1개 Fold를 **훈련 세트**로 사용합니다.
3.  **성능 평균 계산**: K번의 반복을 통해 얻은 **K개의 평가 점수를 평균**내어 모델의 최종 성능으로 삼습니다.

#### **(4) 장점**
*   **신뢰성 높은 성능 측정**: 데이터 분할에 따른 성능 변동을 줄여, 모델의 일반화 성능을 더 안정적으로 추정할 수 있습니다.
*   **효율적인 데이터 활용**: 모든 데이터가 최소 한 번은 훈련과 검증에 모두 사용되므로, 데이터가 적을 때 특히 유용합니다.

---

### **3. 핵심 관계 요약**

| 구분 | **오프라인 테스트 (Offline Test)** | **교차 검증 (Cross-Validation)** |
| :--- | :--- | :--- |
| **범위** | 모델 배포 전 **전체 평가 단계** | 오프라인 테스트 내에서 사용되는 **구체적인 평가 기법** |
| **목적** | 모델이 배포할 만한 최소 성능을 가졌는지 **빠르고 안전하게 검증** | 데이터 분할의 우연성을 줄여 **성능 측정의 신뢰도를 높임** |
| **관계** | 교차 검증을 **포함하는** 더 넓은 개념 | 오프라인 테스트의 **신뢰도를 높여주는** 핵심 도구 |

**비유**: 오프라인 테스트가 '자동차 출시 전 안전 성능 테스트'라는 **전체 과정**이라면, 교차 검증은 그 안에서 '다양한 각도와 속도로 충돌 테스트를 여러 번 실시하여 평균적인 안전 점수를 계산하는' **구체적인 행위**와 같습니다.

---

# Regression (회귀)

## 1. Regression의 정의

회귀(Regression)는 통계학에서 가장 널리 사용되는 기법 중 하나로, 하나 이상의 **독립 변수(independent variables)**와 **종속 변수(dependent variable)** 사이의 관계를 모델링하는 분석 방법입니다. 주요 목표는 독립 변수의 값을 기반으로 **연속적인(continuous)** 종속 변수의 값을 예측하는 것입니다.

- **종속 변수 (Dependent Variable, Y):** 예측하고자 하는 대상이 되는 변수입니다. (예: 주택 가격, 학생의 시험 성적)
- **독립 변수 (Independent Variable, X):** 종속 변수를 설명하거나 예측하는 데 사용되는 변수입니다. (예: 주택의 크기, 학생의 공부 시간)

회귀 분석은 변수들 간의 관계를 파악하고, 특정 조건에서 미래 값을 예측하는 데 강력한 도구로 사용됩니다.

---

## 2. Linear Regression (선형 회귀)

### Linear Relation (선형 관계)

선형 회귀를 이해하기 전에, 변수 간의 **선형 관계(Linear Relation)** 를 이해하는 것이 중요합니다. 두 변수 X와 Y가 선형 관계에 있다는 것은 X의 변화에 따라 Y가 일정한 비율로 변화하는 것을 의미하며, 이는 좌표 평면 상에서 **직선**으로 표현될 수 있습니다.

이를 수학적으로 표현하면 다음과 같은 직선 방정식으로 나타낼 수 있습니다.

`Y ≈ β₀ + β₁X`

- `β₀` (베타 제로): **절편 (Intercept)**. 독립 변수 X가 0일 때의 종속 변수 Y의 예측 값입니다.
- `β₁` (베타 원): **계수 (Coefficient) 또는 기울기 (Slope)**. 독립 변수 X가 한 단위 증가할 때 종속 변수 Y가 변화하는 양을 나타냅니다.

### Linear Regression의 개념

**선형 회귀(Linear Regression)**는 독립 변수와 종속 변수 사이에 **선형 관계가 있다고 가정**하고, 주어진 데이터를 가장 잘 설명하고 예측하는 직선(또는 고차원에서는 초평면)을 찾는 과정입니다. 이 직선을 "회귀선(Regression Line)"이라고 부릅니다.

데이터 포인트들은 보통 완벽한 직선 위에 존재하지 않으므로, 모델은 실제 값과 모델이 예측한 값 사이에 오차(error)를 포함하게 됩니다. 선형 회귀의 목표는 이러한 오차들의 합을 최소화하는 최적의 계수(`β₀`와 `β₁`)를 찾아내는 것입니다.

### Simple Linear Regression (단순 선형 회귀)

**단순 선형 회귀(Simple Linear Regression)**는 선형 회귀의 가장 기본적인 형태로, **하나의 독립 변수(X)**만을 사용하여 **하나의 종속 변수(Y)**를 예측하는 모델입니다.

모델의 수식은 다음과 같이 표현됩니다.

`Y = β₀ + β₁X + ε`

- **Y:** 종속 변수 (실제 값)
- **X:** 독립 변수
- **β₀:** 모델의 절편 (Intercept)
- **β₁:** 독립 변수 X의 계수 (Coefficient)
- **ε (엡실론):** **오차 항(Error Term)**. 모델이 설명하지 못하는 모든 것을 나타냅니다. 여기에는 측정되지 않은 변수의 영향, 데이터의 무작위성 등이 포함됩니다. 실제 값과 모델의 예측 값(`β₀ + β₁X`) 사이의 차이를 의미하며, 통계적으로 특정 가정을 따릅니다 (예: 평균이 0인 정규분포).

단순 선형 회귀의 목표는 주어진 데이터 (X, Y)에 대해 **잔차 제곱합(Sum of Squared Residuals)** 을 최소화하는 `β₀`와 `β₁`를 찾는 것입니다. 이 방법을 **최소제곱법(Ordinary Least Squares, OLS)** 이라고 하며, 이 방법으로 찾은 회귀선이 주어진 데이터를 가장 잘 대표한다고 말할 수 있습니다.

---

## 3. MSE (Mean Squared Error)

**MSE (Mean Squared Error, 평균 제곱 오차)** 는 회귀 모델의 성능을 평가하는 대표적인 지표입니다. 모델의 예측 값과 실제 값의 차이를 측정하여, 모델이 얼마나 데이터를 잘 예측하는지를 정량적으로 보여줍니다.

MSE는 각 데이터 포인트에 대한 **오차(Error)를 제곱(Squared)하여 모두 더한 뒤, 전체 데이터 개수로 나누어 평균(Mean)**을 낸 값입니다.

### MSE의 수식

데이터 포인트가 `n`개 있을 때, MSE의 수식은 다음과 같습니다.

```
MSE = (1/n) * Σ(yᵢ - ŷᵢ)²
```

- `n`: 전체 데이터 포인트의 개수
- `yᵢ`: i번째 데이터 포인트의 **실제 값 (Actual Value)**
- `ŷᵢ` (y-hat): 모델이 예측한 i번째 데이터 포인트의 **예측 값 (Predicted Value)**
- `(yᵢ - ŷᵢ)`: i번째 데이터 포인트의 **오차 (Error) 또는 잔차 (Residual)**

### MSE의 특징

- **오차 부호의 제거:** 오차를 제곱하기 때문에, 예측 값이 실제 값보다 크든 작든 모든 오차는 양수로 처리됩니다.
- **큰 오차에 대한 페널티:** 오차를 제곱하므로, 오차의 크기가 클수록 MSE 값에 더 큰 영향을 미칩니다. 즉, 모델이 큰 실수를 할수록 더 높은 페널티를 받게 됩니다.
- **값의 해석:** MSE 값은 작을수록 모델의 예측이 실제 값에 가깝다는 것을 의미하며, 이는 모델의 성능이 더 좋다는 것을 나타냅니다. MSE가 0이라면 모델이 모든 데이터를 완벽하게 예측했다는 뜻입니다.

선형 회귀에서 **최소제곱법(OLS)**의 목표는 바로 이 **MSE를 최소화하는 회귀선(직선)의 계수 `β₀`와 `β₁`를 찾는 것**입니다.